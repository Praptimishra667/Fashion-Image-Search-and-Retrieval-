{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KQjxp4fD9NCe"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load the model, embeddings, and filenames\n",
        "def load_model_and_data():\n",
        "    # Load the embeddings and filenames\n",
        "    feature_list = np.array(pickle.load(open('embeddings.pkl', 'rb')))\n",
        "    filenames = pickle.load(open('filenames.pkl', 'rb'))\n",
        "\n",
        "    # Load the pre-trained ResNet50 model\n",
        "    model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    model.trainable = False  # Disable training for this model\n",
        "\n",
        "    # Add a GlobalMaxPooling2D layer to the model\n",
        "    model = tf.keras.Sequential([model, GlobalMaxPooling2D()])\n",
        "\n",
        "    return model, feature_list, filenames\n"
      ],
      "metadata": {
        "id": "YUyCBBWf98YP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess the input image\n",
        "def preprocess_image(img_path):\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    expanded_img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    preprocessed_img = preprocess_input(expanded_img_array)  # Normalize the image for ResNet50\n",
        "    return preprocessed_img\n"
      ],
      "metadata": {
        "id": "dkl_oYU4-AxE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract and normalize features from the image\n",
        "def extract_features(model, preprocessed_img):\n",
        "    # Extract the features using the model\n",
        "    result = model.predict(preprocessed_img).flatten()\n",
        "    normalized_result = result / norm(result)  # Normalize the feature vector\n",
        "    return normalized_result\n"
      ],
      "metadata": {
        "id": "9wFw9FWH-EFO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find the nearest neighbors\n",
        "def find_nearest_neighbors(feature_list, query_features, n_neighbors=6):\n",
        "    # Use NearestNeighbors to find the most similar images\n",
        "    neighbors = NearestNeighbors(n_neighbors=n_neighbors, algorithm='brute', metric='euclidean')\n",
        "    neighbors.fit(feature_list)  # Fit the Nearest Neighbors model\n",
        "    distances, indices = neighbors.kneighbors([query_features])  # Get distances and indices of nearest neighbors\n",
        "    return distances, indices\n"
      ],
      "metadata": {
        "id": "MgSELh6g-HEn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display images using matplotlib\n",
        "def display_images(indices, filenames, start=1, end=6):\n",
        "    # Loop through the nearest neighbors and display the images\n",
        "    for file in indices[0][start:end]:  # Skip the first image (query image)\n",
        "        temp_img = cv2.imread(filenames[file])  # Read image using OpenCV\n",
        "        temp_img_rgb = cv2.cvtColor(temp_img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for matplotlib\n",
        "        plt.imshow(cv2.resize(temp_img_rgb, (512, 512)))  # Resize image for display\n",
        "        plt.axis('off')  # Hide axes\n",
        "        plt.show()  # Show the image\n"
      ],
      "metadata": {
        "id": "2h2DW4ai-KBO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main script execution\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Load model and pre-saved data\n",
        "        model, feature_list, filenames = load_model_and_data()\n",
        "\n",
        "        # Preprocess the image to be queried\n",
        "        preprocessed_img = preprocess_image('1164.jpg')\n",
        "\n",
        "        # Extract the features from the preprocessed image\n",
        "        query_features = extract_features(model, preprocessed_img)\n",
        "\n",
        "        # Ensure the extracted features are a 1D array of 2048 elements\n",
        "        if query_features.shape[0] != 2048:\n",
        "            raise ValueError(f\"Expected 2048 features, got {query_features.shape[0]}\")\n",
        "\n",
        "        # Find the nearest neighbors based on the extracted features\n",
        "        distances, indices = find_nearest_neighbors(feature_list, query_features)\n",
        "\n",
        "        # Print the indices of the nearest images (for debugging)\n",
        "        print(\"Indices of nearest images:\", indices)\n",
        "\n",
        "        # Display the nearest images using matplotlib\n",
        "        display_images(indices, filenames)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\", str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JQ-cO8p-PgI",
        "outputId": "3660daf8-1c59-424a-edb6-b462643549ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: [Errno 2] No such file or directory: 'embeddings.pkl'\n"
          ]
        }
      ]
    }
  ]
}